import cv2
import cvlib as cv
from cvlib.object_detection import draw_bbox
import pyttsx3
import numpy as np
import os
import face_recognition
import glob

class SimpleFacerec:
    def __init__(self):
        self.known_face_encodings = []
        self.known_face_names = []
        self.frame_resizing = 0.25

    def load_encoding_images(self, images_path):
        images_files = glob.glob(os.path.join(images_path, "*.*"))
        print(f"{len(images_files)} encoding images found.")

        for img_path in images_files:
            img = cv2.imread(img_path)
            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            basename = os.path.basename(img_path)
            filename, ext = os.path.splitext(basename)
            img_encodings = face_recognition.face_encodings(rgb_img)
            if img_encodings:
                img_encoding = img_encodings[0]
                self.known_face_encodings.append(img_encoding)
                self.known_face_names.append(filename)
            else:
                print(f"No face found in image {img_path}")

        print("Encoding images loaded")

    def detect_known_faces(self, frame):
        small_frame = cv2.resize(frame, (0, 0), fx=self.frame_resizing, fy=self.frame_resizing)
        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        face_locations = face_recognition.face_locations(rgb_small_frame)
        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)
        face_names = []

        for face_encoding in face_encodings:
            matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)
            name = "Unknown"
            face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)
            best_match_index = np.argmin(face_distances)
            if matches[best_match_index]:
                name = self.known_face_names[best_match_index]
            face_names.append(name)

        face_locations = np.array(face_locations)
        face_locations = face_locations / self.frame_resizing
        return face_locations.astype(int), face_names

def speech(text):
    print(text)
    engine = pyttsx3.init()
    engine.say(text)
    engine.runAndWait()

# YOLO configuration paths
config_path = 'C:/Users/kb290/Desktop/Python/Object_Detection/yolo/yolov4.cfg'
weights_path = 'C:/Users/kb290/Desktop/Python/Object_Detection/yolo/yolov4.weights'
labels_path = 'C:/Users/kb290/Desktop/Python/Object_Detection/yolo/coco.names'

if not (os.path.exists(config_path) and os.path.exists(weights_path) and os.path.exists(labels_path)):
    raise FileNotFoundError("One or more YOLO files not found. Please check the paths.")

net = cv2.dnn.readNetFromDarknet(config_path, weights_path)

with open(labels_path, 'r') as f:
    class_labels = f.read().strip().split('\n')

# Face recognition setup
sfr = SimpleFacerec()
sfr.load_encoding_images(r"\\KAVYA\Users\kb290\Desktop\Python\Face-recognition\images")

# Video capture
video = cv2.VideoCapture(0)
labels = []

while True:
    ret, frame = video.read()
    if not ret:
        break

    # Object Detection
    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)
    net.setInput(blob)
    ln = net.getLayerNames()
    ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]
    layer_outputs = net.forward(ln)

    boxes = []
    confidences = []
    class_ids = []
    H, W = frame.shape[:2]

    for output in layer_outputs:
        for detection in output:
            scores = detection[5:]
            class_id = int(scores.argmax())
            confidence = scores[class_id]
            if confidence > 0.5:
                box = detection[0:4] * np.array([W, H, W, H])
                (centerX, centerY, width, height) = box.astype('int')
                x = int(centerX - (width / 2))
                y = int(centerY - (height / 2))
                boxes.append([x, y, int(width), int(height)])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    if len(idxs) > 0:
        for i in idxs.flatten():
            (x, y) = (boxes[i][0], boxes[i][1])
            (w, h) = (boxes[i][2], boxes[i][3])
            color = [int(c) for c in np.random.randint(0, 255, size=(3,))]
            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
            text = f"{class_labels[class_ids[i]]}: {confidences[i]:.4f}"
            cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            if class_labels[class_ids[i]] not in labels:
                labels.append(class_labels[class_ids[i]])

    # Face Recognition
    face_locations, face_names = sfr.detect_known_faces(frame)
    for face_loc, name in zip(face_locations, face_names):
        y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]
        cv2.putText(frame, name, (x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 200), 2)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 200), 4)

    cv2.imshow("Object and Face Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

video.release()
cv2.destroyAllWindows()

new_sentence = [f"I found {label}" for label in labels]
speech(", ".join(new_sentence))
